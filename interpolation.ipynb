{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptpl import PyTorchPipeline\n",
    "from dataset import get_loaders, ds\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import random\n",
    "random.seed(43)\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 49884/135842 [00:00<00:00, 498771.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences is 135842 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135842/135842 [00:00<00:00, 255605.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size if 5384 \n",
      "\n",
      "The size of the newly created text data is 122885, 90% of the original text\n"
     ]
    }
   ],
   "source": [
    "perSentence, vocab = get_loaders()\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "hidden_dim = 32\n",
    "emb_dim = 32\n",
    "nfe = 50\n",
    "\n",
    "hparams = {\n",
    "    'wb' : False,\n",
    "    'span_size': 30,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'emb_dim': emb_dim,\n",
    "    'nfe': nfe,\n",
    "    'gpu_num': 0,\n",
    "    'num_epochs': 100,\n",
    "    'num_batches' : 256,\n",
    "    'path2load': \"./weights/hidden_size_\" + str(hidden_dim) + \"_emb_dim_\" + str(emb_dim) + \"_nfe_\" + str(nfe) + \".pt\",\n",
    "    'learning_rate': 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\" + str(hparams['gpu_num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, hparams['emb_dim']),\n",
    "    Encoder(hparams['emb_dim'], hparams['hidden_dim']),\n",
    "    Decoder(hparams['hidden_dim'], vocab_size, hparams['span_size'], device, hparams['nfe']),\n",
    ")\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch pipeline for gru_node is set up\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = hparams['learning_rate'])\n",
    "\n",
    "\n",
    "# define PyTorch pipeline\n",
    "ptpl = PyTorchPipeline(\n",
    "    project_name = \"gru_node\",\n",
    "    configs = {\n",
    "        'device': device,\n",
    "        'criterion': criterion,\n",
    "        'optimizer': optimizer,\n",
    "        'train_dataloader': perSentence,\n",
    "        'print_logs': True,\n",
    "        'wb': hparams['wb'],\n",
    "    },\n",
    "    hparams = hparams,\n",
    "    model = model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSentences = random.sample(perSentence[5], k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you re the oldest . <EOS>\n",
      "i love this store . <EOS>\n",
      "whose clock is it ? <EOS>\n",
      "i don t belong . <EOS>\n",
      "i m from brazil . <EOS>\n",
      "i was busy cooking . <EOS>\n",
      "that s not interesting . <EOS>\n",
      "it was no accident . <EOS>\n",
      "go grab a drink . <EOS>\n",
      "they looked very happy . <EOS>\n"
     ]
    }
   ],
   "source": [
    "for sampleSentence in sampleSentences:\n",
    "    sampleSentence = \" \".join([vocab.itos[w] for w in sampleSentence])\n",
    "    print(sampleSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.cat([torch.tensor(s).view(1, -1) for s in sampleSentences])\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptpl.load(hparams['path2load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = ptpl.predict(batch, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, selected_output_data = ptpl.compute_loss(batch, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you you just just just re re re re re re re re re teased spoiling spoiling the the the the the the the the oldest oldest oldest oldest oldest oldest oldest oldest oldest contract contract contract . . . . . . . . . <EOS> <EOS> <EOS> <EOS>\n",
      "you re the oldest . <EOS>\n",
      " \n",
      "i i i i i love love love love love love love love love on on this this this this this this this this store store store store store store store store store drawer shelf . . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "i love this store . <EOS>\n",
      " \n",
      "whose whose whose whose whose whose bicycle clock clock clock clock clock clock clock umbrella is is is is is is is up s it it it it it it it it it it it it it ? ? ? ? ? ? ? ? ? <EOS> <EOS> <EOS> <EOS>\n",
      "whose clock is it ? <EOS>\n",
      " \n",
      "i i i just just don don don don don don don don don t t t t t t t t t speak belong belong belong belong belong belong belong belong belong jump spaghetti spaghetti spaghetti . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "i don t belong . <EOS>\n",
      " \n",
      "i i i have m m m m m m m m like loved loved loved from from from from from from from from from from brazil brazil brazil brazil brazil brazil brazil brazil brazil brazil folded . . . . . . . . . <EOS> <EOS> <EOS> <EOS>\n",
      "i m from brazil . <EOS>\n",
      " \n",
      "i i the <UNK> was was was was was was was was was was was busy busy busy busy busy busy busy busy busy working working cooking cooking cooking cooking cooking cooking cooking knives tonight . . . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "i was busy cooking . <EOS>\n",
      " \n",
      "that that that that that that that s s s s s s did did could not not not not not not not so very very very interesting interesting interesting interesting interesting interesting interesting confident discovery . . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "that s not interesting . <EOS>\n",
      " \n",
      "it that his mother mother was was was was was was was was no no no no no no no no no no only bright bright bright years years accident accident accident accident accident accident ago ago . . . . . . . . . <EOS> <EOS> <EOS> <EOS>\n",
      "it was no accident . <EOS>\n",
      " \n",
      "go go let let put put grab grab grab grab grab grab grab travel a a a a a a a a a a drink drink drink drink drink drink drink towel towel breakdown . . . . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "go grab a drink . <EOS>\n",
      " \n",
      "they they just looked looked looked looked looked looked looked looked looked looked looked looked looked looked very very very very very very very very happy happy happy happy happy happy happy ending . . . . . . . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "they looked very happy . <EOS>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "temp = output_data.transpose(1, 0).argmax(2)\n",
    "for i in range(10):\n",
    "    sampleSentence = \" \".join([vocab.itos[w] for w in sampleSentences[i]])\n",
    "    torch_sentence = temp[i].cpu()\n",
    "    torch_sentence = \" \".join([vocab.itos[torch_sentence[i].item()] for i in range(torch_sentence.shape[0])])\n",
    "    print(torch_sentence)\n",
    "    print(sampleSentence)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
