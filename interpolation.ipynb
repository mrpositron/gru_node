{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dataset.dataset import *\n",
    "from pytorch_pipeline.ptpl import PyTorchPipeline\n",
    "from model.model import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "emb_dim = 32\n",
    "\n",
    "hparams = {\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'emb_dim': emb_dim,\n",
    "    'num_batches' : 32,\n",
    "    'path2load': \"./weights/hidden_size_\" + str(hidden_dim) + \"_emb_dim_\" + str(emb_dim) + \".pt\",\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences is 135842 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135842/135842 [00:00<00:00, 580348.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size if 5384 \n",
      "\n",
      "The size of the newly created text data is 122885, 90% of the original text\n",
      "Size of the training data:  98310\n",
      "Size of the validation data:  24575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "\n",
    "path = os.path.join(\"./data\", \"eng-fra.txt\")\n",
    "perSentence, vocab = load_data(path)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "\n",
    "for key, values in perSentence.items():\n",
    "    arr = values[:]\n",
    "    random.shuffle(arr)\n",
    "\n",
    "    val_size = int(0.2 * len(arr))\n",
    "\n",
    "    val_arr = arr[:val_size]\n",
    "    train_arr = arr[val_size:]\n",
    "\n",
    "    train_data[key] = train_arr[:]\n",
    "    val_data[key] = val_arr[:]\n",
    "\n",
    "train_size = sum([len(value) for value in train_data.values() ])\n",
    "val_size = sum([len(value) for value in val_data.values() ])\n",
    "\n",
    "\n",
    "print(\"Size of the training data: \", train_size)\n",
    "print(\"Size of the validation data: \", val_size)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (embedding): Embedding(5384, 32)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(32, 64)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (ode_solve): Neural ODE:\n",
       "    \t- order: 1        \n",
       "    \t- solver: RungeKutta4()\n",
       "    \t- adjoint solver: RungeKutta4()        \n",
       "    \t- tolerances: relative 0.001 absolute 0.001        \n",
       "    \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "    \t- num_parameters: 8320        \n",
       "    \t- NFE: 0.0\n",
       "    (fc): Linear(in_features=64, out_features=5384, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a model\n",
    "embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "encoder = Encoder(emb_dim, hidden_dim)\n",
    "decoder = Decoder(hidden_dim, vocab_size)\n",
    "model = Seq2Seq(embedding, encoder, decoder)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch pipeline for gru_node is set up\n"
     ]
    }
   ],
   "source": [
    "ptpl = PyTorchPipeline(\n",
    "    project_name = \"gru_node\",\n",
    "    configs = {\n",
    "        'device': device,\n",
    "        'criterion': None,\n",
    "        'optimizer': None,\n",
    "        'train_dataloader': train_data,\n",
    "        'val_dataloader': val_data,\n",
    "        'print_logs': True,\n",
    "        'wb': False,\n",
    "    },\n",
    "    hparams = hparams,\n",
    "    model = model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSentences = random.sample(perSentence[5], k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i don t date . <EOS>\n",
      "who s in control ? <EOS>\n",
      "your cough worries me . <EOS>\n",
      "the pain was unbearable . <EOS>\n",
      "i like your style . <EOS>\n",
      "he s a <UNK> . <EOS>\n",
      "anyone can do it . <EOS>\n",
      "you ve been infected . <EOS>\n",
      "i love traveling alone . <EOS>\n",
      "what station is it ? <EOS>\n"
     ]
    }
   ],
   "source": [
    "for sampleSentence in sampleSentences:\n",
    "    sampleSentence = \" \".join([vocab.itos[w] for w in sampleSentence])\n",
    "    print(sampleSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.cat([torch.tensor(s).view(1, -1) for s in sampleSentences])\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptpl.load(hparams['path2load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = ptpl.predict(batch, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 5384])\n"
     ]
    }
   ],
   "source": [
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "i don t date . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "who s in control ? <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "your cough worries me . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "the pain was unbearable . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "i like your style . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "he s a <UNK> . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "anyone can do it . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "you ve been infected . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "i love traveling alone . <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "what station is it ? <EOS>\n",
      "<EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "temp = output_data.transpose(1, 0).argmax(2)\n",
    "print(temp.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    ground_truth_sentence = \" \".join([vocab.itos[w] for w in sampleSentences[i]])\n",
    "    torch_sentence = temp[i].cpu()\n",
    "    sentence = \" \".join([vocab.itos[w.item()] for w in torch_sentence])\n",
    "    print(sentence)\n",
    "#     print(torch_sentence)\n",
    "#     print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
